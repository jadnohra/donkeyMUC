{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [https://github.com/naokishibuya/car-finding-lane-lines/blob/master/Finding%20Lane%20Lines%20on%20the%20Road.ipynb](https://github.com/naokishibuya/car-finding-lane-lines/blob/master/Finding%20Lane%20Lines%20on%20the%20Road.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-02T16:49:36.582538",
     "start_time": "2016-12-02T16:49:34.592060"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "g_silent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_(images, cmap=None):\n",
    "    cols = 2\n",
    "    rows = (len(images)+1)//cols\n",
    "    \n",
    "    plt.figure(figsize=(10, 11))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        # use gray scale color map if there is only one channel\n",
    "        cmap = 'gray' if len(image.shape)==2 else cmap\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "    \n",
    "def show_images(images, cmap=None):\n",
    "    if not g_silent:\n",
    "        show_images(images, cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [plt.imread(path) for path in glob.glob('data/test_images/*.jpg')]\n",
    "show_images(test_images[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hls(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "show_images(list(map(convert_hls, test_images))[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_white_yellow(image):\n",
    "    converted = convert_hls(image)\n",
    "    # white color mask\n",
    "    lower = np.uint8([  0, 200,   0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(converted, lower, upper)\n",
    "    # yellow color mask\n",
    "    lower = np.uint8([ 10,   0, 100])\n",
    "    upper = np.uint8([ 40, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted, lower, upper)\n",
    "    # combine the mask\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    return cv2.bitwise_and(image, image, mask = mask)\n",
    "\n",
    "white_yellow_images = list(map(select_white_yellow, test_images))\n",
    "show_images(white_yellow_images[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gray_scale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "gray_images = list(map(convert_gray_scale, white_yellow_images))\n",
    "show_images(gray_images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smoothing(image, kernel_size=15):\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "blurred_images = list(map(lambda image: apply_smoothing(image), gray_images))\n",
    "show_images(blurred_images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(image, low_threshold=50, high_threshold=150):\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "edge_images = list(map(lambda image: detect_edges(image), blurred_images))\n",
    "show_images(edge_images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_region(image, vertices):\n",
    "    mask = np.zeros_like(image)\n",
    "    if len(mask.shape)==2:\n",
    "        cv2.fillPoly(mask, vertices, 255)\n",
    "    else:\n",
    "        cv2.fillPoly(mask, vertices, (255,)*mask.shape[2]) # in case, the input image has a channel dimension        \n",
    "    return cv2.bitwise_and(image, mask)\n",
    "\n",
    "    \n",
    "def select_region(image):\n",
    "    # first, define the polygon by vertices\n",
    "    rows, cols = image.shape[:2]\n",
    "    bottom_left  = [cols*0.1, rows*0.95]\n",
    "    top_left     = [cols*0.3, rows*0.7]\n",
    "    bottom_right = [cols*0.9, rows*0.95]\n",
    "    top_right    = [cols*0.7, rows*0.7] \n",
    "    # the vertices are an array of polygons (i.e array of arrays) and the data type must be integer\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    return filter_region(image, vertices)\n",
    "\n",
    "roi_images = list(map(select_region, edge_images))\n",
    "show_images(roi_images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hough_lines(image):\n",
    "    return cv2.HoughLinesP(image, rho=1, theta=np.pi/180, threshold=20, minLineLength=20, maxLineGap=300)\n",
    "\n",
    "list_of_lines = list(map(hough_lines, roi_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(image, lines, color=[255, 0, 0], thickness=2, make_copy=True):\n",
    "    # the lines returned by cv2.HoughLinesP has the shape (-1, 1, 4)\n",
    "    if make_copy:\n",
    "        image = np.copy(image) # don't want to modify the original\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    return image\n",
    "\n",
    "line_images = []\n",
    "for image, lines in zip(test_images, list_of_lines):\n",
    "    line_images.append(draw_lines(image, lines))\n",
    "show_images(line_images[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue here, from here in we have to to it differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging and Extrapolating Lines\n",
    "\n",
    "There are multiple lines detected for a lane line.  We should come up with an averaged line for that.\n",
    "\n",
    "Also, some lane lines are only partially recognized.  We should extrapolate the line to cover full lane line length.\n",
    "\n",
    "We want two lane lines: one for the left and the other for the right.  The left lane should have a positive slope, and the right lane should have a negative slope.  Therefore, we'll collect positive slope lines and negative slope lines separately and take averages.\n",
    "\n",
    "Note: in the image, `y` coordinate is reversed.  The higher `y` value is actually lower in the image.  Therefore, the slope is negative for the left lane, and the slope is positive for the right lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_slope_intercept(lines):\n",
    "    left_lines    = [] # (slope, intercept)\n",
    "    left_weights  = [] # (length,)\n",
    "    right_lines   = [] # (slope, intercept)\n",
    "    right_weights = [] # (length,)\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x2==x1:\n",
    "                continue # ignore a vertical line\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            intercept = y1 - slope*x1\n",
    "            length = np.sqrt((y2-y1)**2+(x2-x1)**2)\n",
    "            if slope < 0: # y is reversed in image\n",
    "                left_lines.append((slope, intercept))\n",
    "                left_weights.append((length))\n",
    "            else:\n",
    "                right_lines.append((slope, intercept))\n",
    "                right_weights.append((length))\n",
    "    \n",
    "    # add more weight to longer lines    \n",
    "    left_lane  = np.dot(left_weights,  left_lines) /np.sum(left_weights)  if len(left_weights) >0 else None\n",
    "    right_lane = np.dot(right_weights, right_lines)/np.sum(right_weights) if len(right_weights)>0 else None\n",
    "    \n",
    "    return left_lane, right_lane # (slope, intercept), (slope, intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above `average_lines` function, we can calculate average slope and intercept for the left and right lanes of each image.  \n",
    "\n",
    "Let's draw the lanes.  I need to convert the slope and intercept into pixel points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_line_points(y1, y2, line):\n",
    "    \"\"\"\n",
    "    Convert a line represented in slope and intercept into pixel points\n",
    "    \"\"\"\n",
    "    if line is None:\n",
    "        return None\n",
    "    \n",
    "    slope, intercept = line\n",
    "    \n",
    "    # make sure everything is integer as cv2.line requires it\n",
    "    x1 = int((y1 - intercept)/slope)\n",
    "    x2 = int((y2 - intercept)/slope)\n",
    "    y1 = int(y1)\n",
    "    y2 = int(y2)\n",
    "    \n",
    "    return ((x1, y1), (x2, y2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
